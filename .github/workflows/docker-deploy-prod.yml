name: Deploy Docker Prod For Several Mig

on:
  workflow_dispatch:
    inputs:
      be_version:
        description: 'Î∞∞Ìè¨Ìï† BE docker Î≤ÑÏ†Ñ (Ïòà: 1.2.3)'
        required: true
      fe_version:
        description: 'Î∞∞Ìè¨Ìï† FE Î≤ÑÏ†Ñ (Ïòà: 1.2.3)'
        required: true
      fe_slot:
        description: 'FE Ïä¨Î°Ø ÏÑ†ÌÉù (Ïòà: blue, green)'
        required: true
        default: 'green'
        
jobs:
  deploy:
    runs-on: ubuntu-latest
    outputs:
      fe_slot: ${{ steps.vars.outputs.fe_slot }}

    env:
      AWS_DEFAULT_REGION: ap-northeast-2
      REGION: asia-northeast3
      GH_FE_REPO: 100-hours-a-week/16-Hot6-fe

    steps:
      - name: Checkout Infra Repo
        uses: actions/checkout@v3

      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.GCP_SA_KEY }}'

      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Set variables
        id: vars
        run: |
          RAW_BE_VERSION="${{ github.event.inputs.be_version }}"
          BE_VERSION="v$RAW_BE_VERSION"
          FE_VERSION="${{ github.event.inputs.fe_version }}"
          FE_SLOT="${{ github.event.inputs.fe_slot }}"
          REGION="${{ env.REGION }}"
      
          MIG_NAME="onthetop-mig-prod"
      
          echo "be_version=$BE_VERSION" >> $GITHUB_OUTPUT
          echo "fe_version=$FE_VERSION" >> $GITHUB_OUTPUT
          echo "fe_slot=$FE_SLOT" >> $GITHUB_OUTPUT
          echo "region=$REGION" >> $GITHUB_OUTPUT
          echo "mig_name=$MIG_NAME" >> $GITHUB_OUTPUT

      # ------------------ FE ÏóÖÎ°úÎìú ------------------

      - name: Download FE artifact from GitHub Release
        run: |
          curl -L -o fe.zip https://github.com/$GH_FE_REPO/releases/download/v${{ steps.vars.outputs.fe_version }}/frontend-prod-build.zip
          unzip -o fe.zip -d fe-dist

      - name: Upload FE to S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_KEY }}
          AWS_DEFAULT_REGION: ap-northeast-2
        run: |
          aws s3 sync fe-dist/ s3://onthe-top/frontend/prod/${{ steps.vars.outputs.fe_slot }} --delete

      # ------------------ BE Î∞∞Ìè¨ ------------------

      - name: Find all instance IPs from MIG
        id: get_ips
        run: |
          MIG="${{ steps.vars.outputs.mig_name }}"
          REGION="${{ steps.vars.outputs.region }}"

          echo " Getting instance from MIG: $MIG in $REGION"

          INSTANCE_NAMES=$(gcloud compute instance-groups managed list-instances "$MIG" \
            --region="$REGION" \
            --format="get(instance)" | sed -n 's|.*/||p')

          if [ -z "$INSTANCE_NAMES" ]; then
            echo "‚ùå MIG Ïù∏Ïä§ÌÑ¥Ïä§Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. MIG Ïù¥Î¶ÑÍ≥º REGIONÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî."
            exit 1
          fi

          ZONE_CANDIDATES=("asia-northeast3-a" "asia-northeast3-b" "asia-northeast3-c")

          IP_LIST=""
          for INSTANCE in $INSTANCE_NAMES; do
            for TRY_ZONE in "${ZONE_CANDIDATES[@]}"; do
              IP=$(gcloud compute instances describe "$INSTANCE" --zone "$TRY_ZONE" \
                --format="get(networkInterfaces[0].networkIP)" 2>/dev/null) || continue
              if [ -n "$IP" ]; then
                echo "‚úÖ $INSTANCE ($TRY_ZONE) ‚Üí $IP"
                IP_LIST+="$IP,"
                break
              fi
            done
          done

          IP_LIST="${IP_LIST%,}"

          echo "üì¶ All IPs: $IP_LIST"
          echo "slot_ips=$IP_LIST" >> $GITHUB_OUTPUT

      - name: Set up SSH keys
        run: |
          mkdir -p ~/.ssh

          echo "${{ secrets.JUMP_SSH_KEY }}" > ~/.ssh/jump_key
          chmod 600 ~/.ssh/jump_key

          echo "${{ secrets.SSH_KEY }}" > ~/.ssh/dev_key
          chmod 600 ~/.ssh/dev_key

      - name: Deploy to All MIG Instances via Jump Host
        env:
          SLOT_IPS: ${{ steps.get_ips.outputs.slot_ips }}
          BE_VERSION: ${{ steps.vars.outputs.be_version }}
          JUMP_HOST: ${{ secrets.JUMP_SSH_HOST }}
        run: |
          mkdir -p ~/.ssh
          ssh-keyscan -H "$JUMP_HOST" >> ~/.ssh/known_hosts
          echo "üì¶ SLOT_IPS Í∞í: $SLOT_IPS"
          IFS=',' read -ra IPS <<< "$SLOT_IPS"
          echo "üîç Î∂ÑÌï¥Îêú IP Î∞∞Ïó¥: ${IPS[@]}"
          echo "üîç Î∞∞Ïó¥ Í∏∏Ïù¥: ${#IPS[@]}"

          for IP in "${IPS[@]}"; do
            # ssh-keyscan -H "$IP" >> ~/.ssh/known_hosts || echo "‚ö†Ô∏è ssh-keyscan Ïã§Ìå®: $IP"
            echo "üöÄ Deploying to $IP..."
            ssh -o StrictHostKeyChecking=no \
                -o UserKnownHostsFile=/dev/null \
                -o ProxyCommand="ssh -i ~/.ssh/jump_key -W %h:%p ubuntu@$JUMP_HOST" -i ~/.ssh/dev_key ubuntu@$IP \
                BE_VERSION=$BE_VERSION bash -s <<'EOF'
                set -ex


                SLOTS_RUNNING=$(sudo docker ps --format '{{.Names}}' | grep '^onthetop-backend-' | wc -l)
                INSTANCE_NAME=$(hostname) 
                if [ "$SLOTS_RUNNING" -gt 1 ]; then
                  echo "‚ùå Error: '$INSTANCE_NAME' Ïù∏Ïä§ÌÑ¥Ïä§ÏóêÏÑú Ïù¥ÎØ∏ Ïã§ÌñâÏ§ëÏù∏ ÎèÑÏª§Í∞Ä 2Í∞úÏûÖÎãàÎã§."
                  sudo docker ps --format '  ‚Üí {{.Names}}  ({{.Status}})' | grep '^  ‚Üí onthetop-backend-'
                  exit 1
                fi

                # üîç ÌòÑÏû¨ Ïã§Ìñâ Ï§ëÏù∏ Ïä¨Î°Ø ÌôïÏù∏
                CURRENT_SLOT=$(sudo docker ps --format '{{.Names}}' | grep onthetop-backend- | sed 's/onthetop-backend-//')
                echo "ÌòÑÏû¨ Ïã§Ìñâ Ï§ëÏù∏ Ïª®ÌÖåÏù¥ÎÑà: $CURRENT_SLOT"
                if [ -z "$CURRENT_SLOT" ]; then
                  echo " Ïã§Ìñâ Ï§ëÏù∏ Ïª®ÌÖåÏù¥ÎÑàÍ∞Ä ÏóÜÏäµÎãàÎã§. Í∏∞Î≥∏Í∞íÏúºÎ°ú blue ÏÑ†ÌÉù"
                  CURRENT_SLOT="none"
                  NEW_SLOT="blue"
                  PORT=8080
                elif [ "$CURRENT_SLOT" = "blue" ]; then
                  NEW_SLOT="green"
                  PORT=8081
                else
                  NEW_SLOT="blue"
                  PORT=8080
                fi

                echo " ÌòÑÏû¨ Ïä¨Î°Ø: $CURRENT_SLOT ‚Üí ÏÉà Ïä¨Î°Ø: $NEW_SLOT (Ìè¨Ìä∏: $PORT)"

                # üê≥ Docker Ïù¥ÎØ∏ÏßÄ Pull & Ïã§Ìñâ
                sudo docker rm -f "onthetop-backend-$NEW_SLOT" || true
                sudo docker pull luckyprice1103/onthetop-backend:$BE_VERSION
                sudo docker run -d \
                  --name "onthetop-backend-$NEW_SLOT" \
                  -p "$PORT":8080 \
                  --memory=512m \
                  --cpus=0.5 \
                  -v /home/ubuntu/backend/secrets.properties:/app/secrets.properties \
                  -v /var/log/onthetop/backend:/logs \
                  -e SPRING_PROFILES_ACTIVE=prod \
                  luckyprice1103/onthetop-backend:$BE_VERSION \
                  --logging.file.name=/logs/backend.log \
                  --spring.config.additional-location=file:/app/secrets.properties

                # ‚úÖ Health check
                STATUS="000"
                for i in {1..10}; do
                  echo " [$i/10] Checking health on port $PORT..."
                  STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:$PORT/api/v1/health || echo "000")
                  if [ "$STATUS" = "200" ]; then
                    echo "‚úÖ Health check passed!"
                    break
                  fi
                  sleep 10
                done

                if [ "$STATUS" != "200" ]; then
                  echo "‚ùå Health check failed after 10 attempts."
                  exit 1
                fi

                # üîÅ Nginx ÏÑ§Ï†ï Î≥ÄÍ≤Ω
                echo "üîÅ Switching Nginx to $NEW_SLOT (port $PORT)..."
                NGINX_CONF="/etc/nginx/sites-enabled/backend"

                echo "server {
                  listen 80;
                  server_name _;
                  location / {
                    proxy_pass http://localhost:$PORT;
                    proxy_set_header Host \$host;
                    proxy_set_header X-Real-IP \$remote_addr;
                    proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
                  }
                }" | sudo tee "$NGINX_CONF" > /dev/null

                echo "‚úÖ Nginx config updated to route to port $PORT"
                echo "üîÑ Reloading Nginx..."
                sudo nginx -t
                sudo systemctl reload nginx
          EOF
          done


      # ------------------ CloudFront Origin Î≥ÄÍ≤Ω Î∞è Î¨¥Ìö®Ìôî ------------------

  cdn-update:
    needs: deploy
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.CLOUDFRONT_ACCESS_KEY }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.CLOUDFRONT_SECRET_KEY }}
      AWS_DEFAULT_REGION: ap-northeast-2
      CLOUDFRONT_DISTRIBUTION_ID: ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}
    steps:
      - name: Update CloudFront Origin
        run: |
          SLOT="${{ needs.deploy.outputs.fe_slot }}"
          DIST_ID="$CLOUDFRONT_DISTRIBUTION_ID"

          # ÏõêÎ≥∏ Ï†ÑÏ≤¥ Íµ¨ÏÑ± Î∞õÏïÑÏò§Í∏∞
          aws cloudfront get-distribution-config --id $DIST_ID > raw.json

          # ETag Ï∂îÏ∂ú
          ETAG=$(jq -r '.ETag' raw.json)

          # DistributionConfigÎßå Ï∂îÏ∂ú
          jq '.DistributionConfig' raw.json > config-only.json

          # OriginPath ÏàòÏ†ï
          jq --arg SLOT "$SLOT" \
            '.Origins.Items[0].OriginPath = "/frontend/prod/\($SLOT)"' \
            config-only.json > updated-config.json

          # ÏóÖÎç∞Ïù¥Ìä∏ Ï†ÅÏö©
          aws cloudfront update-distribution \
            --id $DIST_ID \
            --if-match $ETAG \
            --distribution-config file://updated-config.json

      - name: Invalidate CloudFront cache
        run: |
          SLOT="${{ needs.deploy.outputs.fe_slot }}"
          aws cloudfront create-invalidation \
            --distribution-id "$CLOUDFRONT_DISTRIBUTION_ID" \
            --paths "/" "/index.html" "/assets/*.js" "/assets/*.css"
